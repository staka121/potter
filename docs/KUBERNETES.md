# Potter & Kubernetes

> **Potter's Multi-Environment Philosophy: Same Definition, Different Targets**

Potter is designed to support both local development and production deployment from a single Tsubo definition, with Kubernetes as the primary production target.

## Overview

Potter seamlessly integrates with Kubernetes while maintaining simplicity for local development:

- ðŸ  **Local Development**: Docker Compose + gateway-service
- â˜ï¸ **Production**: Kubernetes + Ingress
- ðŸ“ **Single Source**: One `.tsubo.yaml` file for both environments

## Architecture Comparison

### Local Development (Docker Compose)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Developer Laptop                        â”‚
â”‚                                          â”‚
â”‚  potter run app.tsubo.yaml               â”‚
â”‚         â†“                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ gateway-service  â”‚ :8080              â”‚
â”‚  â”‚  (Auto-started)  â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚           â”‚                              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                        â”‚
â”‚     â–¼           â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  user  â”‚ â”‚  todo  â”‚                   â”‚
â”‚  â”‚ :8084  â”‚ â”‚ :8083  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                          â”‚
â”‚  Access: http://localhost:8080           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Characteristics:**
- âœ… Simple: Single command to start everything
- âœ… Fast: No cluster setup required
- âœ… Unified: Single entry point (localhost:8080)
- âœ… Isolated: Runs in Docker containers

### Production (Kubernetes)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kubernetes Cluster                      â”‚
â”‚                                          â”‚
â”‚  potter deploy generate --ingress        â”‚
â”‚         â†“                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚     Ingress      â”‚                    â”‚
â”‚  â”‚ (nginx/traefik)  â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚           â”‚                              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                        â”‚
â”‚     â–¼           â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ user-  â”‚ â”‚ todo-  â”‚                   â”‚
â”‚  â”‚ serviceâ”‚ â”‚ serviceâ”‚                   â”‚
â”‚  â”‚  Pods  â”‚ â”‚  Pods  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                          â”‚
â”‚  Access: https://api.example.com         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Characteristics:**
- âœ… Scalable: Auto-scaling with HPA
- âœ… Resilient: Self-healing and rolling updates
- âœ… Production-grade: Battle-tested Ingress Controllers
- âœ… Secure: TLS termination, network policies

## Gateway Comparison

### gateway-service (Docker Compose)

**What it is:**
- Custom Go application that acts as a reverse proxy
- Auto-generated and auto-started by Potter
- Routes traffic to backend services

**Routing Logic:**
```go
/api/v1/users/* â†’ user-service:8084
/api/v1/todos/* â†’ todo-service:8083
/health         â†’ gateway health check
```

**When to use:**
- Local development with `potter run`
- Simple deployment scenarios
- Docker Compose environments

**Pros:**
- Zero configuration
- Works everywhere Docker runs
- Simple debugging

**Cons:**
- Custom code to maintain
- Limited scalability
- No built-in TLS/auth

### Ingress (Kubernetes)

**What it is:**
- Kubernetes native resource
- Uses proven Ingress Controllers (nginx, Traefik, etc.)
- Generated by Potter from Tsubo definition

**Routing Logic:**
```yaml
/api/v1/users(/|$)(.*) â†’ user-service:80
/api/v1/todos(/|$)(.*) â†’ todo-service:80
```

**When to use:**
- Kubernetes deployments
- Production environments
- Need for advanced features (TLS, auth, rate limiting)

**Pros:**
- Production-grade
- Rich ecosystem (cert-manager, OAuth, etc.)
- Native K8s integration
- Battle-tested at scale

**Cons:**
- Requires Kubernetes cluster
- More complex setup initially

## Multi-Environment Workflow

### 1. Define Once

Create your Tsubo definition:

```yaml
# app.tsubo.yaml
tsubo:
  name: my-app

objects:
  - name: user-service
    contract: ./user-service.object.yaml
    runtime:
      port: 8080
      health_check: /health
    dependencies: []

  - name: todo-service
    contract: ./todo-service.object.yaml
    runtime:
      port: 8080
      health_check: /health
    dependencies:
      - user-service
```

### 2. Develop Locally

```bash
# AI generates implementation
potter build app.tsubo.yaml

# Start with Docker Compose + gateway-service
potter run app.tsubo.yaml

# Access via unified endpoint
curl http://localhost:8080/api/v1/users
curl http://localhost:8080/api/v1/todos
```

### 3. Deploy to Kubernetes

```bash
# Generate K8s manifests with Ingress
potter deploy generate \
  --namespace production \
  --ingress-host api.example.com \
  --registry docker.io/myorg \
  --tag v1.0.0 \
  app.tsubo.yaml

# Apply to cluster
kubectl apply -f k8s/

# Access via Ingress
curl https://api.example.com/api/v1/users
```

## Deployment Options

### Basic Deployment

Generate manifests with default settings:

```bash
potter deploy generate app.tsubo.yaml
```

Generates:
- Namespace
- Deployments (1 replica each)
- Services (ClusterIP)
- Ingress (nginx, default host)

### Production Deployment

Full production configuration:

```bash
potter deploy generate \
  --namespace production \
  --ingress-host api.prod.example.com \
  --ingress-class nginx \
  --registry gcr.io/my-project \
  --tag v1.2.3 \
  --replicas 3 \
  --output k8s-prod \
  app.tsubo.yaml
```

### Without Ingress

Use gateway-service in Kubernetes (not recommended):

```bash
potter deploy generate \
  --ingress=false \
  app.tsubo.yaml
```

## Generated Resources

Potter generates standard Kubernetes resources:

### Namespace

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: potter-todo
  labels:
    app.kubernetes.io/managed-by: potter
```

### Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: user-service
        image: docker.io/myorg/user-service:v1.0.0
        ports:
        - containerPort: 8080
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
        env:
        - name: TODO_SERVICE_URL
          value: "http://todo-service.potter-todo.svc.cluster.local"
```

**Key Features:**
- Auto-generated health probes from `health_check`
- Service dependencies â†’ environment variables
- Resource limits (requests/limits)
- Standard K8s labels

### Service

```yaml
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8080
  selector:
    app: user-service
```

### Ingress

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: "/$2"
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /api/v1/users(/|$)(.*)
        backend:
          service:
            name: user-service
            port:
              number: 80
      - path: /api/v1/todos(/|$)(.*)
        backend:
          service:
            name: todo-service
            port:
              number: 80
```

**Key Features:**
- Automatic path inference from service names
- Regex-based routing with URL rewriting
- Configurable Ingress Controller (nginx, Traefik, etc.)
- Optional TLS configuration

## Design Philosophy

### 1. Contract-Driven K8s Manifests

Potter generates K8s resources from your Contract definitions:

```
Contract Definition (Human/AI readable)
           â†“
    Tsubo Parser
           â†“
   K8s Generator
           â†“
Standard K8s Manifests
```

This ensures:
- âœ… Single source of truth
- âœ… Consistency across environments
- âœ… Version controlled configuration
- âœ… AI can understand and modify

### 2. Gateway Abstraction

Potter abstracts the gateway concept:

```
Tsubo Definition
      â†“
   [Potter]
      â†“
   â”œâ”€â†’ Docker Compose â†’ gateway-service
   â””â”€â†’ Kubernetes     â†’ Ingress
```

**Benefits:**
- Developers think in terms of services, not infrastructure
- Same routing logic, different implementation
- Optimal gateway for each environment

### 3. Progressive Enhancement

Start simple, scale when needed:

```
Day 1: potter run (Docker Compose)
         â†“
Week 1: Add more services
         â†“
Month 1: potter deploy generate (K8s staging)
         â†“
Month 3: Production with HPA, TLS, monitoring
```

### 4. Convention over Configuration

Potter makes intelligent defaults:

- Service name â†’ API path inference
  - `user-service` â†’ `/api/v1/users`
  - `product-service` â†’ `/api/v1/products`
- Health check â†’ liveness/readiness probes
- Dependencies â†’ environment variables
- Standard ports and protocols

## Best Practices

### 1. Environment Parity

Keep development and production as similar as possible:

```bash
# Use the same Tsubo definition
potter run app.tsubo.yaml              # Local
potter deploy generate app.tsubo.yaml  # Production
```

### 2. Version Control Everything

```
my-app/
â”œâ”€â”€ app.tsubo.yaml          # Application definition
â”œâ”€â”€ user-service.object.yaml # Contract definitions
â”œâ”€â”€ todo-service.object.yaml
â””â”€â”€ k8s/                    # Generated (gitignored)
    â”œâ”€â”€ namespace.yaml
    â”œâ”€â”€ deployment-*.yaml
    â”œâ”€â”€ service-*.yaml
    â””â”€â”€ ingress.yaml
```

Add to `.gitignore`:
```
k8s/
```

Regenerate manifests in CI/CD:
```bash
potter deploy generate --tag $GIT_SHA app.tsubo.yaml
```

### 3. Use Feature Flags, Not Branches

```yaml
# app.tsubo.yaml
objects:
  - name: new-feature-service
    contract: ./new-feature.object.yaml
    # Deploy to dev/staging first
```

### 4. Gradual Rollout

```bash
# Stage 1: Dev environment
potter deploy generate \
  --namespace dev \
  --ingress-host api.dev.example.com \
  app.tsubo.yaml

# Stage 2: Staging
potter deploy generate \
  --namespace staging \
  --ingress-host api.staging.example.com \
  --replicas 2 \
  app.tsubo.yaml

# Stage 3: Production
potter deploy generate \
  --namespace production \
  --ingress-host api.example.com \
  --replicas 5 \
  app.tsubo.yaml
```

## Advanced Topics

### TLS Configuration

```bash
# Generate with TLS placeholder
potter deploy generate \
  --ingress-host api.example.com \
  app.tsubo.yaml

# Add cert-manager annotation manually
# (Future: --ingress-tls flag)
```

### Custom Ingress Annotations

Edit generated `ingress.yaml`:

```yaml
metadata:
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
```

### Multiple Environments

Use output directories:

```bash
potter deploy generate --output k8s-dev app.tsubo.yaml
potter deploy generate --output k8s-staging app.tsubo.yaml
potter deploy generate --output k8s-prod app.tsubo.yaml
```

### Helm Chart Generation

(Future enhancement)

```bash
potter deploy generate --helm app.tsubo.yaml
```

## Troubleshooting

### Ingress Not Working

```bash
# Check Ingress Controller is installed
kubectl get pods -n ingress-nginx

# Check Ingress resource
kubectl describe ingress -n potter-todo

# Check service endpoints
kubectl get endpoints -n potter-todo
```

### Service Not Accessible

```bash
# Check pods are running
kubectl get pods -n potter-todo

# Check pod logs
kubectl logs -n potter-todo deployment/user-service

# Test service directly (port-forward)
kubectl port-forward -n potter-todo svc/user-service 8080:80
curl http://localhost:8080/health
```

### Gateway-service vs Ingress Conflict

If you see both gateway-service and Ingress:

```bash
# Regenerate with --ingress (default)
potter deploy generate --ingress app.tsubo.yaml

# gateway-service will be automatically skipped
```

## Future Enhancements

- [ ] `potter deploy apply` - Direct K8s deployment
- [ ] Helm chart generation
- [ ] Horizontal Pod Autoscaler (HPA) configuration
- [ ] ConfigMap/Secret management from Tsubo
- [ ] Service Mesh integration (Istio, Linkerd)
- [ ] GitOps integration (ArgoCD, Flux)

## Summary

Potter's Kubernetes integration embodies the framework's philosophy:

> **Humans define WHAT (contracts, domains)**
> **AI implements HOW (service logic)**
> **Potter bridges WHERE (Docker Compose â‡„ Kubernetes)**

This allows developers to:
- Focus on business logic, not infrastructure
- Use the same definition across all environments
- Adopt Kubernetes progressively, not disruptively
- Maintain the simplicity of local development
- Deploy with confidence to production

---

**Status:** âœ… Production Ready
**Version:** 0.6.0
**Latest Feature:** Ingress generation (replaces gateway-service in K8s)
